"""
–ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞ - –≤—Å—ë –≤ –æ–¥–Ω–æ–º —Å–∫—Ä–∏–ø—Ç–µ.
–ó–∞–ø—É—Å–∫: python scripts/architecture/analyze_all.py
"""

import ast
import json
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Set


class ArchitectureAnalyzer:
    """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞."""
    
    def __init__(self, src_dir: Path = Path("src")):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è."""
        self.src_dir = src_dir
        self.results = {
            "modules": {},
            "dependencies": {},
            "complexity": {},
            "issues": [],
            "recommendations": []
        }
    
    def analyze_all(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ –∞–Ω–∞–ª–∏–∑—ã."""
        print("=" * 80)
        print("–ê–ù–ê–õ–ò–ó –ê–†–•–ò–¢–ï–ö–¢–£–†–´ –ü–†–û–ï–ö–¢–ê")
        print("=" * 80)
        print()
        
        print("1. –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥—É–ª–µ–π...")
        self.analyze_module_structure()
        
        print("\n2. –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")
        self.analyze_dependencies()
        
        print("\n3. –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏...")
        self.analyze_complexity()
        
        print("\n4. –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º...")
        self.identify_issues()
        
        print("\n5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
        self.generate_recommendations()
        
        self.save_results()
        self.print_summary()
    
    def analyze_module_structure(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–æ–¥—É–ª–µ–π."""
        modules = {}
        
        for item in self.src_dir.iterdir():
            if item.is_dir() and not item.name.startswith('__'):
                py_files = list(item.rglob("*.py"))
                modules[item.name] = {
                    "files": len(py_files),
                    "lines": sum(self._count_lines(f) for f in py_files),
                    "subdirs": len([d for d in item.iterdir() if d.is_dir()])
                }
        
        self.results["modules"] = modules
        
        # –¢–æ–ø-5 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö –º–æ–¥—É–ª–µ–π
        top_modules = sorted(
            modules.items(),
            key=lambda x: x[1]["files"],
            reverse=True
        )[:5]
        
        print("  –¢–æ–ø-5 –º–æ–¥—É–ª–µ–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ñ–∞–π–ª–æ–≤:")
        for name, data in top_modules:
            print(f"    {name}: {data['files']} —Ñ–∞–π–ª–æ–≤, {data['lines']} —Å—Ç—Ä–æ–∫")
    
    def analyze_dependencies(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –º–æ–¥—É–ª—è–º–∏."""
        dependencies = defaultdict(set)
        
        for py_file in self.src_dir.rglob("*.py"):
            if "__pycache__" in str(py_file):
                continue
            
            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    tree = ast.parse(f.read())
                
                module_name = self._get_module_name(py_file)
                
                for node in ast.walk(tree):
                    if isinstance(node, (ast.Import, ast.ImportFrom)):
                        imported = self._get_imported_module(node)
                        if imported and imported != module_name:
                            dependencies[module_name].add(imported)
            
            except Exception:
                pass
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è set –≤ list –¥–ª—è JSON
        self.results["dependencies"] = {
            k: list(v) for k, v in dependencies.items()
        }
        
        # –ü–æ–∏—Å–∫ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        cycles = self._find_cycles(dependencies)
        if cycles:
            print(f"  ‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: {len(cycles)}")
        else:
            print("  ‚úÖ –¶–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    def analyze_complexity(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∫–æ–¥–∞."""
        complexity_data = {}
        
        for py_file in self.src_dir.rglob("*.py"):
            if "__pycache__" in str(py_file):
                continue
            
            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    tree = ast.parse(f.read())
                
                # –ü–æ–¥—Å—á—ë—Ç —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤
                functions = sum(1 for node in ast.walk(tree) 
                              if isinstance(node, ast.FunctionDef))
                classes = sum(1 for node in ast.walk(tree) 
                            if isinstance(node, ast.ClassDef))
                
                if functions > 0 or classes > 0:
                    module = self._get_module_name(py_file)
                    if module not in complexity_data:
                        complexity_data[module] = {
                            "functions": 0,
                            "classes": 0,
                            "files": 0
                        }
                    
                    complexity_data[module]["functions"] += functions
                    complexity_data[module]["classes"] += classes
                    complexity_data[module]["files"] += 1
            
            except Exception:
                pass
        
        self.results["complexity"] = complexity_data
        
        # –¢–æ–ø-5 —Å–∞–º—ã—Ö —Å–ª–æ–∂–Ω—ã—Ö –º–æ–¥—É–ª–µ–π
        top_complex = sorted(
            complexity_data.items(),
            key=lambda x: x[1]["functions"] + x[1]["classes"],
            reverse=True
        )[:5]
        
        print("  –¢–æ–ø-5 –º–æ–¥—É–ª–µ–π –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏:")
        for name, data in top_complex:
            total = data["functions"] + data["classes"]
            print(f"    {name}: {total} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ ({data['functions']} —Ñ—É–Ω–∫—Ü–∏–π, {data['classes']} –∫–ª–∞—Å—Å–æ–≤)")
    
    def identify_issues(self):
        """–í—ã—è–≤–ª—è–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã."""
        issues = []
        
        # –ü—Ä–æ–±–ª–µ–º–∞ 1: –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –º–æ–¥—É–ª–µ
        for name, data in self.results["modules"].items():
            if data["files"] > 100:
                issues.append({
                    "severity": "high",
                    "module": name,
                    "issue": f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ñ–∞–π–ª–æ–≤ ({data['files']})",
                    "recommendation": "–†–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ –ø–æ–¥–º–æ–¥—É–ª–∏"
                })
        
        # –ü—Ä–æ–±–ª–µ–º–∞ 2: –ë–æ–ª—å—à–æ–π main.py
        main_py = self.src_dir / "main.py"
        if main_py.exists():
            lines = self._count_lines(main_py)
            if lines > 500:
                issues.append({
                    "severity": "medium",
                    "module": "main",
                    "issue": f"main.py —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({lines} —Å—Ç—Ä–æ–∫)",
                    "recommendation": "–í—ã–Ω–µ—Å—Ç–∏ –ª–æ–≥–∏–∫—É –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏"
                })
        
        # –ü—Ä–æ–±–ª–µ–º–∞ 3: –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª–µ–π
        module_names = list(self.results["modules"].keys())
        similar = self._find_similar_names(module_names)
        for group in similar:
            if len(group) > 1:
                issues.append({
                    "severity": "low",
                    "module": ", ".join(group),
                    "issue": "–ü–æ—Ö–æ–∂–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–¥—É–ª–µ–π",
                    "recommendation": "–í–æ–∑–º–æ–∂–Ω–æ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –∏–ª–∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å"
                })
        
        self.results["issues"] = issues
        
        print(f"  –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(issues)}")
        for issue in issues[:5]:
            print(f"    [{issue['severity']}] {issue['module']}: {issue['issue']}")
    
    def generate_recommendations(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."""
        recommendations = []
        
        # –ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞ modules
        if "modules" in self.results["modules"]:
            files = self.results["modules"]["modules"]["files"]
            if files > 100:
                recommendations.append({
                    "priority": "critical",
                    "action": "–†–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏—è modules/",
                    "description": f"–†–∞–∑–¥–µ–ª–∏—Ç—å {files} —Ñ–∞–π–ª–æ–≤ –Ω–∞ –¥–æ–º–µ–Ω–Ω—ã–µ –ø–æ–¥–º–æ–¥—É–ª–∏",
                    "effort": "high"
                })
        
        # –ù–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        dep_count = len(self.results["dependencies"])
        if dep_count > 50:
            recommendations.append({
                "priority": "medium",
                "action": "–£–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏",
                "description": "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –º–µ–∂–º–æ–¥—É–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π",
                "effort": "medium"
            })
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations.append({
            "priority": "high",
            "action": "–í–Ω–µ–¥—Ä–∏—Ç—å Dependency Injection",
            "description": "–£–ª—É—á—à–∏—Ç —Ç–µ—Å—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ –º–æ–¥—É–ª—å–Ω–æ—Å—Ç—å",
            "effort": "medium"
        })
        
        recommendations.append({
            "priority": "medium",
            "action": "–°–æ–∑–¥–∞—Ç—å architecture tests",
            "description": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª",
            "effort": "low"
        })
        
        self.results["recommendations"] = recommendations
        
        print(f"  –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(recommendations)}")
        for rec in recommendations:
            print(f"    [{rec['priority']}] {rec['action']}")
    
    def save_results(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
        output_file = Path("architecture_analysis.json")
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
    
    def print_summary(self):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É."""
        print()
        print("=" * 80)
        print("–ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê")
        print("=" * 80)
        print()
        
        print(f"–ú–æ–¥—É–ª–µ–π: {len(self.results['modules'])}")
        print(f"–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: {len(self.results['dependencies'])}")
        print(f"–ü—Ä–æ–±–ª–µ–º: {len(self.results['issues'])}")
        print(f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(self.results['recommendations'])}")
        
        print()
        print("–ö—Ä–∏—Ç–∏—á–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:")
        for rec in self.results["recommendations"]:
            if rec["priority"] == "critical":
                print(f"  üî¥ {rec['action']}")
        
        print()
        print("=" * 80)
    
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    
    def _count_lines(self, filepath: Path) -> int:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ–∞–π–ª–µ."""
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                return len(f.readlines())
        except:
            return 0
    
    def _get_module_name(self, filepath: Path) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–º—è –º–æ–¥—É–ª—è –∏–∑ –ø—É—Ç–∏."""
        try:
            rel_path = filepath.relative_to(self.src_dir)
            parts = rel_path.parts
            if len(parts) > 0:
                return parts[0]
        except:
            pass
        return "unknown"
    
    def _get_imported_module(self, node) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–º—è –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º–æ–≥–æ –º–æ–¥—É–ª—è."""
        if isinstance(node, ast.ImportFrom):
            if node.module and node.module.startswith("src."):
                parts = node.module.split(".")
                if len(parts) > 1:
                    return parts[1]
        elif isinstance(node, ast.Import):
            for alias in node.names:
                if alias.name.startswith("src."):
                    parts = alias.name.split(".")
                    if len(parts) > 1:
                        return parts[1]
        return None
    
    def _find_cycles(self, dependencies: Dict[str, Set[str]]) -> List[List[str]]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏."""
        cycles = []
        visited = set()
        
        def dfs(node, path):
            if node in path:
                cycle_start = path.index(node)
                cycle = path[cycle_start:]
                if cycle not in cycles:
                    cycles.append(cycle)
                return
            
            if node in visited:
                return
            
            visited.add(node)
            path.append(node)
            
            for dep in dependencies.get(node, []):
                dfs(dep, path.copy())
        
        for node in dependencies:
            dfs(node, [])
        
        return cycles
    
    def _find_similar_names(self, names: List[str]) -> List[List[str]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è."""
        similar = []
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∫–æ—Ä–Ω–∏
        roots = defaultdict(list)
        for name in names:
            root = name.split("_")[0]
            roots[root].append(name)
        
        for group in roots.values():
            if len(group) > 1:
                similar.append(group)
        
        return similar


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    analyzer = ArchitectureAnalyzer()
    analyzer.analyze_all()


if __name__ == "__main__":
    main()
