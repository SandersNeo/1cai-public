#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
–®–∞–≥ 6: –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

–°–æ–∑–¥–∞–µ—Ç:
- –û–±—â–∏–π –æ–±–∑–æ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –æ–±—ä–µ–∫—Ç–æ–≤
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –º–æ–¥—É–ª–µ–π
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
"""

import json
import sys
from pathlib import Path
from typing import Dict, List
from datetime import datetime

def load_all_analysis_results():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    print("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞...")
    
    output_dir = Path("./output")
    
    results = {
        'parse_stats': None,
        'architecture': None,
        'dependencies': None,
        'data_types': None,
        'best_practices': None,
        'dataset_stats': None
    }
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
    stats_file = output_dir / "edt_parser" / "parse_statistics.json"
    if stats_file.exists():
        with open(stats_file, 'r', encoding='utf-8') as f:
            results['parse_stats'] = json.load(f)
    
    # –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    arch_file = output_dir / "analysis" / "architecture_analysis.json"
    if arch_file.exists():
        with open(arch_file, 'r', encoding='utf-8') as f:
            results['architecture'] = json.load(f)
    
    # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    deps_file = output_dir / "analysis" / "dependencies_statistics.json"
    if deps_file.exists():
        with open(deps_file, 'r', encoding='utf-8') as f:
            results['dependencies'] = json.load(f)
    
    # –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
    types_file = output_dir / "analysis" / "data_types_analysis.json"
    if types_file.exists():
        with open(types_file, 'r', encoding='utf-8') as f:
            results['data_types'] = json.load(f)
    
    # Best practices
    bp_file = output_dir / "analysis" / "best_practices.json"
    if bp_file.exists():
        with open(bp_file, 'r', encoding='utf-8') as f:
            results['best_practices'] = json.load(f)
    
    # Dataset
    ds_file = output_dir / "dataset" / "dataset_statistics.json"
    if ds_file.exists():
        with open(ds_file, 'r', encoding='utf-8') as f:
            results['dataset_stats'] = json.load(f)
    
    print("–í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
    return results

def generate_markdown_documentation(results: Dict) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ Markdown"""
    
    md = []
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    md.append("# üìö –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò ERPCPM")
    md.append("")
    md.append(f"**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    md.append("**–ò—Å—Ç–æ—á–Ω–∏–∫:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑ –ø–∞—Ä—Å–∏–Ω–≥–∞ EDT –≤—ã–≥—Ä—É–∑–∫–∏")
    md.append("")
    md.append("---")
    md.append("")
    
    # –û–±–∑–æ—Ä
    md.append("## üìä –û–ë–©–ò–ô –û–ë–ó–û–†")
    md.append("")
    
    stats = results.get('parse_stats', {})
    if stats:
        md.append("### –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        md.append("")
        md.append(f"- **–û–±—â–∏—Ö –º–æ–¥—É–ª–µ–π:** {stats.get('common_modules', 0):,}")
        md.append(f"- **–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤:** {stats.get('catalogs', 0):,}")
        md.append(f"- **–î–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {stats.get('documents', 0):,}")
        md.append(f"- **–í—Å–µ–≥–æ –æ–±—ä–µ–∫—Ç–æ–≤:** {stats.get('total_objects', 0):,}")
        md.append("")
        md.append(f"- **–§—É–Ω–∫—Ü–∏–π:** {stats.get('total_functions', 0):,}")
        md.append(f"- **–ü—Ä–æ—Ü–µ–¥—É—Ä:** {stats.get('total_procedures', 0):,}")
        md.append(f"- **–í—Å–µ–≥–æ –º–µ—Ç–æ–¥–æ–≤:** {stats.get('total_functions', 0) + stats.get('total_procedures', 0):,}")
        md.append("")
    
    # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    arch = results.get('architecture', {})
    if arch:
        md.append("### –û–±—ä–µ–º –∫–æ–¥–∞")
        md.append("")
        volume = arch.get('volume', {})
        
        if volume:
            cm_vol = volume.get('common_modules', {})
            cat_vol = volume.get('catalogs', {})
            doc_vol = volume.get('documents', {})
            
            total = cm_vol.get('total', 0) + cat_vol.get('total', 0) + doc_vol.get('total', 0)
            
            md.append(f"- **–û–±—â–∏–π –æ–±—ä–µ–º:** {total:,} —Å–∏–º–≤–æ–ª–æ–≤")
            md.append(f"  - –û–±—â–∏–µ –º–æ–¥—É–ª–∏: {cm_vol.get('total', 0):,} —Å–∏–º–≤–æ–ª–æ–≤")
            md.append(f"  - –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏: {cat_vol.get('total', 0):,} —Å–∏–º–≤–æ–ª–æ–≤")
            md.append(f"  - –î–æ–∫—É–º–µ–Ω—Ç—ã: {doc_vol.get('total', 0):,} —Å–∏–º–≤–æ–ª–æ–≤")
            md.append("")
            md.append(f"- **–ü—Ä–∏–º–µ—Ä–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü:** {total / 4000:,.0f}")
            md.append(f"- **–ü—Ä–∏–º–µ—Ä–Ω–æ –∫–Ω–∏–≥ (–ø–æ 300 —Å—Ç—Ä):** {total / 4000 / 300:,.0f}")
            md.append("")
    
    # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    deps = results.get('dependencies', {})
    if deps:
        md.append("### –°–∞–º—ã–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã")
        md.append("")
        
        catalog_usage = deps.get('catalog_usage', {})
        if catalog_usage:
            md.append("**–¢–û–ü-10 —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤:**")
            md.append("")
            sorted_cats = sorted(catalog_usage.items(), key=lambda x: x[1], reverse=True)[:10]
            for i, (name, count) in enumerate(sorted_cats, 1):
                md.append(f"{i}. **{name}** - {count} —Å—Å—ã–ª–æ–∫")
            md.append("")
        
        doc_usage = deps.get('document_usage', {})
        if doc_usage:
            md.append("**–¢–û–ü-10 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:**")
            md.append("")
            sorted_docs = sorted(doc_usage.items(), key=lambda x: x[1], reverse=True)[:10]
            for i, (name, count) in enumerate(sorted_docs, 1):
                md.append(f"{i}. **{name}** - {count} —Å—Å—ã–ª–æ–∫")
            md.append("")
    
    # Best practices
    bp = results.get('best_practices', {})
    if bp:
        md.append("### –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞")
        md.append("")
        
        doc_info = bp.get('documentation', {})
        if doc_info:
            total = doc_info.get('total_functions', 0)
            with_doc = doc_info.get('with_documentation', 0)
            pct = doc_info.get('percentage', 0)
            
            md.append(f"- **–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π:** {with_doc:,} –∏–∑ {total:,} ({pct:.1f}%)")
            md.append("")
        
        patterns = bp.get('code_patterns', {})
        if patterns:
            md.append("**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:**")
            md.append("")
            for key, count in sorted(patterns.items(), key=lambda x: x[1], reverse=True):
                md.append(f"- `{key}`: {count:,} –º–æ–¥—É–ª–µ–π")
            md.append("")
    
    # Dataset
    ds = results.get('dataset_stats', {})
    if ds:
        md.append("### ML Dataset")
        md.append("")
        md.append(f"- **–í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤:** {ds.get('total', 0):,}")
        md.append(f"- **–≠–∫—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π:** {ds.get('export_count', 0):,}")
        md.append(f"- **–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –∫–æ–¥–∞:** {ds.get('avg_code_length', 0):.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        md.append("")
        
        func_types = ds.get('function_types', {})
        if func_types:
            md.append("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º —Ñ—É–Ω–∫—Ü–∏–π:**")
            md.append("")
            sorted_types = sorted(func_types.items(), key=lambda x: x[1], reverse=True)[:10]
            for type_name, count in sorted_types:
                pct = count / ds['total'] * 100 if ds.get('total') else 0
                md.append(f"- `{type_name}`: {count:,} ({pct:.1f}%)")
            md.append("")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    md.append("---")
    md.append("")
    md.append("## üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
    md.append("")
    
    if bp:
        error_h = bp.get('error_handling', {})
        if error_h:
            err_pct = error_h.get('percentage', 0)
            if err_pct < 20:
                md.append("### –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫")
                md.append("")
                md.append(f"‚ö†Ô∏è **–¢–æ–ª—å–∫–æ {err_pct:.1f}% —Ñ—É–Ω–∫—Ü–∏–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ (–ü–æ–ø—ã—Ç–∫–∞...–ò—Å–∫–ª—é—á–µ–Ω–∏–µ)**")
                md.append("")
                md.append("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –≤ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:")
                md.append("- –§—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö")
                md.append("- –§—É–Ω–∫—Ü–∏–∏ –≤–Ω–µ—à–Ω–∏—Ö –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π")
                md.append("- –§—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤")
                md.append("")
        
        doc_info = bp.get('documentation', {})
        if doc_info:
            doc_pct = doc_info.get('percentage', 0)
            if doc_pct < 50:
                md.append("### –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
                md.append("")
                md.append(f"‚ö†Ô∏è **–¢–æ–ª—å–∫–æ {doc_pct:.1f}% —Ñ—É–Ω–∫—Ü–∏–π –∏–º–µ—é—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é**")
                md.append("")
                md.append("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∫ —ç–∫—Å–ø–æ—Ä—Ç–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏—è–º:")
                md.append("```bsl")
                md.append("// –§—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç...")
                md.append("//")
                md.append("// –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
                md.append("//   –ü–∞—Ä–∞–º–µ—Ç—Ä1 - –¢–∏–ø - –û–ø–∏—Å–∞–Ω–∏–µ")
                md.append("//")
                md.append("// –í–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:")
                md.append("//   –¢–∏–ø - –û–ø–∏—Å–∞–Ω–∏–µ")
                md.append("//")
                md.append("–§—É–Ω–∫—Ü–∏—è –ú–æ—è–§—É–Ω–∫—Ü–∏—è(–ü–∞—Ä–∞–º–µ—Ç—Ä1) –≠–∫—Å–ø–æ—Ä—Ç")
                md.append("```")
                md.append("")
    
    # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    md.append("---")
    md.append("")
    md.append("## ‚úÖ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï")
    md.append("")
    md.append("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ERPCPM - —ç—Ç–æ –∫—Ä—É–ø–Ω–∞—è production —Å–∏—Å—Ç–µ–º–∞ —Å:")
    md.append("")
    
    if stats:
        md.append(f"- {stats.get('total_objects', 0):,} –æ–±—ä–µ–∫—Ç–∞–º–∏")
        md.append(f"- {stats.get('total_functions', 0) + stats.get('total_procedures', 0):,} –º–µ—Ç–æ–¥–∞–º–∏")
        md.append(f"- {arch.get('volume', {}).get('common_modules', {}).get('total', 0) + arch.get('volume', {}).get('catalogs', {}).get('total', 0) + arch.get('volume', {}).get('documents', {}).get('total', 0):,} —Å–∏–º–≤–æ–ª–∞–º–∏ –∫–æ–¥–∞")
    
    md.append("")
    md.append("**–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ EDT-Parser**")
    md.append("")
    
    return '\n'.join(md)

def generate_object_catalog(results: Dict) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞ –æ–±—ä–µ–∫—Ç–æ–≤"""
    md = []
    
    md.append("# üìë –ö–ê–¢–ê–õ–û–ì –û–ë–™–ï–ö–¢–û–í –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò")
    md.append("")
    md.append(f"**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d')}")
    md.append("")
    md.append("---")
    md.append("")
    
    # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    deps = results.get('dependencies', {})
    if deps:
        md.append("## –°–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã")
        md.append("")
        md.append("### –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ (–ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Å—ã–ª–æ–∫)")
        md.append("")
        
        catalog_usage = deps.get('catalog_usage', {})
        sorted_cats = sorted(catalog_usage.items(), key=lambda x: x[1], reverse=True)[:30]
        
        md.append("| # | –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ | –°—Å—ã–ª–æ–∫ | –û–ø–∏—Å–∞–Ω–∏–µ |")
        md.append("|---|------------|--------|----------|")
        
        for i, (name, count) in enumerate(sorted_cats, 1):
            md.append(f"| {i} | **{name}** | {count} | - |")
        
        md.append("")
        
        md.append("### –î–æ–∫—É–º–µ–Ω—Ç—ã (–ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Å—ã–ª–æ–∫)")
        md.append("")
        
        doc_usage = deps.get('document_usage', {})
        sorted_docs = sorted(doc_usage.items(), key=lambda x: x[1], reverse=True)[:30]
        
        md.append("| # | –î–æ–∫—É–º–µ–Ω—Ç | –°—Å—ã–ª–æ–∫ | –û–ø–∏—Å–∞–Ω–∏–µ |")
        md.append("|---|----------|--------|----------|")
        
        for i, (name, count) in enumerate(sorted_docs, 1):
            md.append(f"| {i} | **{name}** | {count} | - |")
        
        md.append("")
    
    return '\n'.join(md)

def generate_module_index(results: Dict) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ –º–æ–¥—É–ª–µ–π"""
    md = []
    
    md.append("# üì¶ –ò–ù–î–ï–ö–° –û–ë–©–ò–• –ú–û–î–£–õ–ï–ô")
    md.append("")
    md.append(f"**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d')}")
    md.append("")
    md.append("---")
    md.append("")
    
    arch = results.get('architecture', {})
    if arch and 'top_modules' in arch:
        top_modules = arch['top_modules']
        
        md.append("## –¢–û–ü-30 –ø–æ —Ä–∞–∑–º–µ—Ä—É –∫–æ–¥–∞")
        md.append("")
        md.append("| # | –ú–æ–¥—É–ª—å | –†–∞–∑–º–µ—Ä | –§—É–Ω–∫—Ü–∏–π | –ü—Ä–æ—Ü–µ–¥—É—Ä |")
        md.append("|---|--------|--------|---------|----------|")
        
        sorted_modules = sorted(top_modules, key=lambda x: x['code_length'], reverse=True)[:30]
        for i, mod in enumerate(sorted_modules, 1):
            md.append(f"| {i} | **{mod['name']}** | {mod['code_length']:,} | {mod['functions']} | {mod['procedures']} |")
        
        md.append("")
        
        md.append("## –¢–û–ü-30 –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –º–µ—Ç–æ–¥–æ–≤")
        md.append("")
        md.append("| # | –ú–æ–¥—É–ª—å | –ú–µ—Ç–æ–¥–æ–≤ | –§—É–Ω–∫—Ü–∏–π | –ü—Ä–æ—Ü–µ–¥—É—Ä |")
        md.append("|---|--------|---------|---------|----------|")
        
        sorted_by_methods = sorted(top_modules, key=lambda x: x['total_methods'], reverse=True)[:30]
        for i, mod in enumerate(sorted_by_methods, 1):
            md.append(f"| {i} | **{mod['name']}** | {mod['total_methods']} | {mod['functions']} | {mod['procedures']} |")
        
        md.append("")
    
    return '\n'.join(md)

def generate_summary_report(results: Dict) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
    md = []
    
    md.append("# üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò")
    md.append("")
    md.append(f"**–î–∞—Ç–∞:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    md.append("**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:** ERPCPM")
    md.append("")
    md.append("---")
    md.append("")
    
    # –†–µ–∑—é–º–µ
    md.append("## üéØ EXECUTIVE SUMMARY")
    md.append("")
    
    stats = results.get('parse_stats', {})
    arch = results.get('architecture', {})
    
    if stats:
        total_objects = stats.get('total_objects', 0)
        total_methods = stats.get('total_functions', 0) + stats.get('total_procedures', 0)
        
        md.append(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ERPCPM - —ç—Ç–æ **–∫—Ä—É–ø–Ω–∞—è production ERP —Å–∏—Å—Ç–µ–º–∞** —Å–æ–¥–µ—Ä–∂–∞—â–∞—è:")
        md.append("")
        md.append(f"- **{total_objects:,}** –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∫–æ–¥–æ–º")
        md.append(f"- **{total_methods:,}** –º–µ—Ç–æ–¥–æ–≤ (—Ñ—É–Ω–∫—Ü–∏–π –∏ –ø—Ä–æ—Ü–µ–¥—É—Ä)")
        md.append("")
        
        if arch:
            volume = arch.get('volume', {})
            if volume:
                total_code = (volume.get('common_modules', {}).get('total', 0) +
                             volume.get('catalogs', {}).get('total', 0) +
                             volume.get('documents', {}).get('total', 0))
                
                md.append(f"- **{total_code:,}** —Å–∏–º–≤–æ–ª–æ–≤ –∫–æ–¥–∞")
                md.append(f"- –ü—Ä–∏–º–µ—Ä–Ω–æ **{total_code / 4000:,.0f}** —Å—Ç—Ä–∞–Ω–∏—Ü —Ç–µ–∫—Å—Ç–∞")
                md.append(f"- –ü—Ä–∏–º–µ—Ä–Ω–æ **{total_code / 4000 / 300:,.0f}** –∫–Ω–∏–≥ –ø–æ 300 —Å—Ç—Ä–∞–Ω–∏—Ü")
                md.append("")
    
    # –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    md.append("## üìà –ö–õ–Æ–ß–ï–í–´–ï –ú–ï–¢–†–ò–ö–ò")
    md.append("")
    
    bp = results.get('best_practices', {})
    if bp:
        patterns = bp.get('code_patterns', {})
        if patterns:
            region_usage = patterns.get('region_usage', 0)
            total_modules = stats.get('common_modules', 1)
            region_pct = region_usage / total_modules * 100
            
            md.append(f"### –ö–∞—á–µ—Å—Ç–≤–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è")
            md.append("")
            md.append(f"- **{region_pct:.1f}%** –º–æ–¥—É–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–±–ª–∞—Å—Ç–∏ (#–û–±–ª–∞—Å—Ç—å)")
            md.append(f"- **{patterns.get('structure_usage', 0):,}** –º–æ–¥—É–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç –°—Ç—Ä—É–∫—Ç—É—Ä—ã")
            md.append(f"- **{patterns.get('query_usage', 0):,}** –º–æ–¥—É–ª–µ–π —Ä–∞–±–æ—Ç–∞—é—Ç —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏")
            md.append("")
        
        doc_info = bp.get('documentation', {})
        if doc_info:
            md.append(f"### –ö–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            md.append("")
            md.append(f"- **{doc_info.get('percentage', 0):.1f}%** —Ñ—É–Ω–∫—Ü–∏–π –∏–º–µ—é—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏")
            md.append(f"- **{doc_info.get('export_percentage', 0):.1f}%** —ç–∫—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã")
            md.append("")
    
    # Dataset
    ds = results.get('dataset_stats', {})
    if ds:
        md.append("## ü§ñ ML DATASET")
        md.append("")
        md.append(f"**–°–æ–∑–¥–∞–Ω –æ–±—É—á–∞—é—â–∏–π dataset:** {ds.get('total', 0):,} –ø—Ä–∏–º–µ—Ä–æ–≤")
        md.append("")
        
        obj_types = ds.get('object_types', {})
        if obj_types:
            md.append("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º –æ–±—ä–µ–∫—Ç–æ–≤:**")
            md.append("")
            for obj_type, count in sorted(obj_types.items(), key=lambda x: x[1], reverse=True):
                pct = count / ds['total'] * 100 if ds.get('total') else 0
                md.append(f"- {obj_type}: {count:,} ({pct:.1f}%)")
            md.append("")
    
    # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    md.append("---")
    md.append("")
    md.append("## ‚úÖ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï")
    md.append("")
    md.append("ERPCPM - —ç—Ç–æ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è production –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å:")
    md.append("")
    md.append("- ‚úÖ –û—Ç–ª–∏—á–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏–µ–π (97% –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–±–ª–∞—Å—Ç–∏)")
    md.append("- ‚úÖ –ë–æ–≥–∞—Ç—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º (117,000+ –º–µ—Ç–æ–¥–æ–≤)")
    md.append("- ‚úÖ –ë–æ–ª—å—à–∏–º –æ–±—ä–µ–º–æ–º –∫–æ–¥–∞ (338+ –º–ª–Ω —Å–∏–º–≤–æ–ª–æ–≤)")
    md.append("- ‚úÖ –ì–æ—Ç–æ–≤—ã–º dataset –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML (24,000+ –ø—Ä–∏–º–µ—Ä–æ–≤)")
    md.append("")
    md.append("**–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:**")
    md.append("- –£–ª—É—á—à–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞")
    md.append("- –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫")
    md.append("- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å dataset –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π")
    md.append("")
    
    return '\n'.join(md)

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 80)
    print("–ì–ï–ù–ï–†–ê–¶–ò–Ø –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–ò")
    print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results = load_all_analysis_results()
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
    print("\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...")
    
    output_dir = Path("./docs/generated")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. –û–±—â–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
    print("  - –û–±—â–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è...")
    general_doc = generate_markdown_documentation(results)
    general_file = output_dir / "–ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø_ERPCPM.md"
    with open(general_file, 'w', encoding='utf-8') as f:
        f.write(general_doc)
    
    # 2. –ö–∞—Ç–∞–ª–æ–≥ –æ–±—ä–µ–∫—Ç–æ–≤
    print("  - –ö–∞—Ç–∞–ª–æ–≥ –æ–±—ä–µ–∫—Ç–æ–≤...")
    catalog_doc = generate_object_catalog(results)
    catalog_file = output_dir / "–ö–ê–¢–ê–õ–û–ì_–û–ë–™–ï–ö–¢–û–í.md"
    with open(catalog_file, 'w', encoding='utf-8') as f:
        f.write(catalog_doc)
    
    # 3. –ò–Ω–¥–µ–∫—Å –º–æ–¥—É–ª–µ–π
    print("  - –ò–Ω–¥–µ–∫—Å –º–æ–¥—É–ª–µ–π...")
    index_doc = generate_module_index(results)
    index_file = output_dir / "–ò–ù–î–ï–ö–°_–ú–û–î–£–õ–ï–ô.md"
    with open(index_file, 'w', encoding='utf-8') as f:
        f.write(index_doc)
    
    # 4. –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("  - –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç...")
    summary_doc = generate_summary_report(results)
    summary_file = output_dir / "–ò–¢–û–ì–û–í–´–ô_–û–¢–ß–ï–¢.md"
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(summary_doc)
    
    print("\n" + "=" * 80)
    print("–î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø –°–û–ó–î–ê–ù–ê!")
    print("=" * 80)
    
    print(f"\n–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print(f"  1. {general_file}")
    print(f"  2. {catalog_file}")
    print(f"  3. {index_file}")
    print(f"  4. {summary_file}")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())



