# ğŸ”§ Apache Airflow - Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¸ Ğ²Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ñ

**Ğ”Ğ°Ñ‚Ğ°:** 2025-11-06  
**Ğ”Ğ»Ñ:** Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚Ğ¾Ğ²  
**Ğ¦ĞµĞ»ÑŒ:** Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¸ "ĞµÑĞ»Ğ¸ Ğ²Ğ½ĞµĞ´Ñ€ÑĞµĞ¼"

---

## ğŸ“‹ Ğ¡Ğ¦Ğ•ĞĞĞ Ğ˜Ğ™ A: ĞœĞ˜ĞĞ˜ĞœĞĞ›Ğ¬ĞĞĞ• Ğ’ĞĞ•Ğ”Ğ Ğ•ĞĞ˜Ğ•

### Ğ§Ñ‚Ğ¾ Ğ²Ğ½ĞµĞ´Ñ€ÑĞµĞ¼:
**Ğ¢ĞĞ›Ğ¬ĞšĞ ML Training Pipeline** (Ğ·Ğ°Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Celery Beat Ğ´Ğ»Ñ ML)

### ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           1C AI STACK (Hybrid)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   Airflow    â”‚      â”‚    Celery     â”‚       â”‚
â”‚  â”‚   (Batch)    â”‚      â”‚  (Real-time)  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                      â”‚                â”‚
â”‚         â”‚                      â”‚                â”‚
â”‚    ML Training          Async API Tasks         â”‚
â”‚    (daily 2 AM)         (<100ms response)       â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Docker Compose:

```yaml
# docker-compose.airflow.yml
services:
  # Airflow Postgres (metadata)
  airflow-postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow-postgres-data:/var/lib/postgresql/data
    
  # Airflow Webserver
  airflow-webserver:
    image: apache/airflow:2.8.0
    depends_on:
      - airflow-postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
    command: webserver
    
  # Airflow Scheduler
  airflow-scheduler:
    image: apache/airflow:2.8.0
    depends_on:
      - airflow-postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
    command: scheduler

volumes:
  airflow-postgres-data:
```

### DAG Ğ´Ğ»Ñ ML Pipeline:

```python
# dags/ml_training_pipeline.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.utils.dates import days_ago
from datetime import timedelta

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
import sys
sys.path.append('/opt/ai-stack/src')
from workers.ml_tasks import (
    update_feature_store,
    check_model_drift,
    retrain_model,
    evaluate_models,
    cleanup_experiments
)

default_args = {
    'owner': '1c-ai-stack',
    'depends_on_past': False,
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'ml_training_daily',
    default_args=default_args,
    description='Daily ML models training and maintenance',
    schedule_interval='0 2 * * *',  # 2 AM daily
    start_date=days_ago(1),
    catchup=False,
    tags=['ml', 'training', 'daily'],
)

# Tasks
update_features_task = PythonOperator(
    task_id='update_feature_store',
    python_callable=update_feature_store,
    dag=dag,
)

check_drift_task = PythonOperator(
    task_id='check_model_drift',
    python_callable=check_model_drift,
    dag=dag,
)

# ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
retrain_model_1 = PythonOperator(
    task_id='retrain_model_classification',
    python_callable=retrain_model,
    op_kwargs={'model_type': 'classification'},
    dag=dag,
)

retrain_model_2 = PythonOperator(
    task_id='retrain_model_regression',
    python_callable=retrain_model,
    op_kwargs={'model_type': 'regression'},
    dag=dag,
)

retrain_model_3 = PythonOperator(
    task_id='retrain_model_clustering',
    python_callable=retrain_model,
    op_kwargs={'model_type': 'clustering'},
    dag=dag,
)

evaluate_task = PythonOperator(
    task_id='evaluate_all_models',
    python_callable=evaluate_models,
    dag=dag,
)

cleanup_task = PythonOperator(
    task_id='cleanup_old_experiments',
    python_callable=cleanup_experiments,
    dag=dag,
)

# Ğ“Ñ€Ğ°Ñ„ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
update_features_task >> check_drift_task
check_drift_task >> [retrain_model_1, retrain_model_2, retrain_model_3]
[retrain_model_1, retrain_model_2, retrain_model_3] >> evaluate_task
evaluate_task >> cleanup_task
```

### Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚:

**Ğ”Ğ¾ (Celery):**
```
Ğ’Ñ€ĞµĞ¼Ñ: 70 Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾
RAM: 350 MB
Visibility: Flower (basic)
```

**ĞŸĞ¾ÑĞ»Ğµ (Airflow):**
```
Ğ’Ñ€ĞµĞ¼Ñ: 40 Ğ¼Ğ¸Ğ½ÑƒÑ‚ (Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼)
RAM: 1,500 MB (+1,150 MB)
Visibility: Rich UI Ñ Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ¼
```

**Trade-off:**
- Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸: -43%
- Ğ—Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ RAM: +329%
- Visibility: +400%

**ĞÑ†ĞµĞ½ĞºĞ°:** ğŸŸ¡ Ğ¡Ğ¿Ğ¾Ñ€Ğ½Ğ¾ (Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ, Ğ½Ğ¾ Ğ´Ğ¾Ñ€Ğ¾Ğ¶Ğµ)

---

## ğŸ“‹ Ğ¡Ğ¦Ğ•ĞĞĞ Ğ˜Ğ™ B: Ğ¡Ğ Ğ•Ğ”ĞĞ•Ğ• Ğ’ĞĞ•Ğ”Ğ Ğ•ĞĞ˜Ğ•

### Ğ§Ñ‚Ğ¾ Ğ²Ğ½ĞµĞ´Ñ€ÑĞµĞ¼:
- ML Training Pipeline (Airflow)
- EDT Analysis Pipeline (Airflow)
- System Tasks (Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Crontab)
- Real-time (Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Celery + AI Orchestrator)

### DAG Ğ´Ğ»Ñ EDT Analysis:

```python
# dags/edt_analysis_pipeline.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from datetime import datetime, timedelta

dag = DAG(
    'edt_analysis_on_demand',
    default_args={'retries': 1},
    description='Full EDT configuration analysis pipeline',
    schedule_interval=None,  # Trigger manually
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['edt', 'analysis', 'manual'],
)

# Ğ¨Ğ°Ğ³ 1: ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³
parse_edt = BashOperator(
    task_id='parse_edt_configuration',
    bash_command='python /opt/ai-stack/scripts/parsers/edt/edt_parser_with_metadata.py',
    dag=dag,
)

# Ğ¨Ğ°Ğ³Ğ¸ 2-5: ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
analyze_architecture = BashOperator(
    task_id='analyze_architecture',
    bash_command='python /opt/ai-stack/scripts/analysis/analyze_architecture.py',
    dag=dag,
)

analyze_dependencies = BashOperator(
    task_id='analyze_dependencies',
    bash_command='python /opt/ai-stack/scripts/analysis/analyze_dependencies.py',
    dag=dag,
)

extract_best_practices = BashOperator(
    task_id='extract_best_practices',
    bash_command='python /opt/ai-stack/scripts/analysis/extract_best_practices.py',
    dag=dag,
)

create_ml_dataset = BashOperator(
    task_id='create_ml_dataset',
    bash_command='python /opt/ai-stack/scripts/dataset/create_ml_dataset.py',
    dag=dag,
)

# Ğ¨Ğ°Ğ³ 6: Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
generate_documentation = BashOperator(
    task_id='generate_documentation',
    bash_command='python /opt/ai-stack/scripts/analysis/generate_documentation.py',
    dag=dag,
)

# Ğ“Ñ€Ğ°Ñ„: Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ â†’ 4 Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° â†’ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
parse_edt >> [analyze_architecture, analyze_dependencies, extract_best_practices, create_ml_dataset]
[analyze_architecture, analyze_dependencies, extract_best_practices, create_ml_dataset] >> generate_documentation
```

### Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚:

**Ğ”Ğ¾ (Manual):**
```
Ğ’Ñ€ĞµĞ¼Ñ: 30-47 Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾
Ğ—Ğ°Ğ¿ÑƒÑĞº: Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ, 6 ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´
ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³: Ğ½ĞµÑ‚
```

**ĞŸĞ¾ÑĞ»Ğµ (Airflow):**
```
Ğ’Ñ€ĞµĞ¼Ñ: 15-20 Ğ¼Ğ¸Ğ½ÑƒÑ‚ (Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼)
Ğ—Ğ°Ğ¿ÑƒÑĞº: 1 ĞºĞ½Ğ¾Ğ¿ĞºĞ° Ğ² UI
ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³: full Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ, Ğ»Ğ¾Ğ³Ğ¸
```

**ĞÑ†ĞµĞ½ĞºĞ°:** âœ… Ğ£Ğ´Ğ¾Ğ±Ğ½ĞµĞµ (Ğ½Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ÑÑ Ñ€ĞµĞ´ĞºĞ¾)

---

## ğŸ“‹ Ğ¡Ğ¦Ğ•ĞĞĞ Ğ˜Ğ™ C: ĞŸĞĞ›ĞĞĞ• Ğ’ĞĞ•Ğ”Ğ Ğ•ĞĞ˜Ğ• (NOT RECOMMENDED)

### Ğ§Ñ‚Ğ¾ Ğ²Ğ½ĞµĞ´Ñ€ÑĞµĞ¼:
**Ğ’Ğ¡Ğ Ğ² Airflow** (ML, ETL, Maintenance, Analysis)

### ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°:

```
Apache Airflow (Master Orchestrator)
â”œâ”€â”€ ML Training DAG (daily)
â”œâ”€â”€ Feature Store Update DAG (hourly)
â”œâ”€â”€ EDT Analysis DAG (on-demand)
â”œâ”€â”€ Data Sync DAG (weekly)
â”œâ”€â”€ Backup DAG (daily)
â”œâ”€â”€ Cleanup DAG (weekly)
â”œâ”€â”€ Security Audit DAG (monthly)
â””â”€â”€ Health Check DAG (every 15 min)

Celery Ğ¾ÑÑ‚Ğ°ĞµÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Real-time
AI Orchestrator Ğ¾ÑÑ‚Ğ°ĞµÑ‚ÑÑ Ğ´Ğ»Ñ user queries
```

### ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹:

1. **Over-engineering**
   - 8+ DAG Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡
   - Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ >> Value

2. **Maintenance overhead**
   - ĞÑƒĞ¶ĞµĞ½ Airflow specialist
   - Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ Ñ‚Ğ¾Ñ‡ĞµĞº Ğ¾Ñ‚ĞºĞ°Ğ·Ğ°

3. **Resource waste**
   - Airflow Ğ´Ğ»Ñ health checks ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 15 Ğ¼Ğ¸Ğ½ = overkill
   - Crontab ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑÑ Ğ»ÑƒÑ‡ÑˆĞµ

**ĞÑ†ĞµĞ½ĞºĞ°:** âŒ ĞĞ• Ğ Ğ•ĞšĞĞœĞ•ĞĞ”Ğ£Ğ•Ğ¢Ğ¡Ğ¯ (too much)

---

## ğŸ’¡ Ğ¡Ğ¦Ğ•ĞĞĞ Ğ˜Ğ™ D: "BEST OF BOTH WORLDS"

### Hybrid Architecture (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµĞ¼Ğ°Ñ):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         1C AI Stack                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  Airflow (Batch Workflows)              â”‚
â”‚  â”œâ”€ ML Training Pipeline (daily)        â”‚
â”‚  â””â”€ EDT Analysis Pipeline (on-demand)   â”‚
â”‚                                          â”‚
â”‚  Celery (Async Tasks)                   â”‚
â”‚  â”œâ”€ Real-time API tasks                 â”‚
â”‚  â”œâ”€ Background processing               â”‚
â”‚  â””â”€ Email/notifications                 â”‚
â”‚                                          â”‚
â”‚  Crontab (Simple Tasks)                 â”‚
â”‚  â”œâ”€ Backups                             â”‚
â”‚  â”œâ”€ Health checks                       â”‚
â”‚  â””â”€ Cleanup                             â”‚
â”‚                                          â”‚
â”‚  AI Orchestrator (Real-time Queries)    â”‚
â”‚  â””â”€ User queries routing                â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ¾ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°:

```python
def choose_orchestrator(task):
    if task.latency_requirement < 1_second:
        return "AI Orchestrator"  # Real-time
    
    elif task.complexity < 5_steps:
        return "Crontab"  # Simple
    
    elif task.frequency == 'continuous':
        return "Celery"  # Async background
    
    elif task.complexity >= 10_steps or task.needs_parallelism:
        return "Airflow"  # Complex batch
    
    else:
        return "Celery"  # Default Ğ´Ğ»Ñ Python tasks
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:**

| Task | Complexity | Latency | Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ |
|------|------------|---------|------------|
| User query | low | <100ms | AI Orchestrator |
| Send email | low | <5s | Celery |
| Daily backup | low | any | Crontab |
| ML training (5 models) | high | hours | **Airflow** â­ |
| EDT full analysis (6 steps) | medium | hours | **Airflow** â­ |
| Health check | low | any | Crontab |

---

## ğŸ” Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞ«Ğ™ ĞĞĞĞ›Ğ˜Ğ—: ML PIPELINE

### Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (Celery):

**Ğ¤Ğ°Ğ¹Ğ»:** `src/workers/ml_tasks.py`

```python
@celery_app.task
def retrain_all_models():
    """
    ĞŸĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ²ÑĞµÑ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹.
    ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ!
    """
    models = ['classification', 'regression', 'clustering', 'ranking', 'recommendation']
    
    for model_type in models:
        logger.info(f"Retraining {model_type}...")
        retrain_model(model_type)  # 15 Ğ¼Ğ¸Ğ½ÑƒÑ‚ ĞºĞ°Ğ¶Ğ´Ğ°Ñ
    
    # Ğ˜Ğ¢ĞĞ“Ğ: 75 Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾!
```

**Bottleneck:** ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ

### Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ Ñ Airflow:

```python
# dags/ml_training_parallel.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.utils.task_group import TaskGroup

dag = DAG('ml_training_parallel', schedule_interval='0 2 * * *')

with TaskGroup('model_training', dag=dag) as training_group:
    models = ['classification', 'regression', 'clustering', 'ranking', 'recommendation']
    
    training_tasks = []
    for model_type in models:
        task = PythonOperator(
            task_id=f'train_{model_type}',
            python_callable=retrain_model,
            op_kwargs={'model_type': model_type},
        )
        training_tasks.append(task)

# Ğ’ÑĞµ 5 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‚ÑÑ ĞŸĞĞ ĞĞ›Ğ›Ğ•Ğ›Ğ¬ĞĞ!
# Ğ’Ñ€ĞµĞ¼Ñ: 15 Ğ¼Ğ¸Ğ½ÑƒÑ‚ (Ğ²Ğ¼ĞµÑÑ‚Ğ¾ 75)
```

**Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚:**
- Ğ‘Ñ‹Ğ»Ğ¾: 75 Ğ¼Ğ¸Ğ½ÑƒÑ‚
- Ğ¡Ñ‚Ğ°Ğ»Ğ¾: 15 Ğ¼Ğ¸Ğ½ÑƒÑ‚
- **Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ: 80%** â­â­â­

**ĞĞ¾ Ğ½ÑƒĞ¶Ğ½Ğ¾:** 4-5 CPU cores Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼Ğ°

---

## ğŸ¯ Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞ«Ğ™ ĞĞĞĞ›Ğ˜Ğ—: EDT PIPELINE

### Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (Manual):

**6 ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ğ², Ğ·Ğ°Ğ¿ÑƒÑĞº Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ:**

```bash
#!/bin/bash
# scripts/run_full_edt_analysis.sh (ĞĞ• Ğ¡Ğ£Ğ©Ğ•Ğ¡Ğ¢Ğ’Ğ£Ğ•Ğ¢ ÑĞµĞ¹Ñ‡Ğ°Ñ!)

echo "Step 1/6: Parsing EDT configuration..."
python scripts/parsers/edt/edt_parser_with_metadata.py
if [ $? -ne 0 ]; then echo "FAILED"; exit 1; fi

echo "Step 2/6: Analyzing architecture..."
python scripts/analysis/analyze_architecture.py
if [ $? -ne 0 ]; then echo "FAILED"; exit 1; fi

echo "Step 3/6: Creating ML dataset..."
python scripts/dataset/create_ml_dataset.py
if [ $? -ne 0 ]; then echo "FAILED"; exit 1; fi

echo "Step 4/6: Analyzing dependencies..."
python scripts/analysis/analyze_dependencies.py
if [ $? -ne 0 ]; then echo "FAILED"; exit 1; fi

echo "Step 5/6: Extracting best practices..."
python scripts/analysis/extract_best_practices.py
if [ $? -ne 0 ]; then echo "FAILED"; exit 1; fi

echo "Step 6/6: Generating documentation..."
python scripts/analysis/generate_documentation.py
if [ $? -ne 0 ]; then echo "FAILED"; exit 1; fi

echo "SUCCESS: Full analysis complete!"

# Ğ˜Ğ¢ĞĞ“Ğ: 30-47 Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾
```

### Ğ¡ Airflow (Ñ ÑƒĞ¼Ğ½Ñ‹Ğ¼ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼Ğ¾Ğ¼):

```python
# dags/edt_full_analysis.py
dag = DAG('edt_analysis', schedule_interval=None, catchup=False)

# Ğ¨Ğ°Ğ³ 1: ĞĞ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹
parse = PythonOperator(task_id='parse_edt', ...)

# Ğ¨Ğ°Ğ³Ğ¸ 2-5: ĞŸĞĞ ĞĞ›Ğ›Ğ•Ğ›Ğ¬ĞĞ (Ğ½Ğµ Ğ·Ğ°Ğ²Ğ¸ÑÑÑ‚ Ğ´Ñ€ÑƒĞ³ Ğ¾Ñ‚ Ğ´Ñ€ÑƒĞ³Ğ°!)
with TaskGroup('parallel_analysis', dag=dag) as parallel:
    analyze_arch = PythonOperator(task_id='architecture', ...)
    create_dataset = PythonOperator(task_id='ml_dataset', ...)
    analyze_deps = PythonOperator(task_id='dependencies', ...)
    extract_bp = PythonOperator(task_id='best_practices', ...)

# Ğ¨Ğ°Ğ³ 6: ĞŸĞ¾ÑĞ»Ğµ Ğ²ÑĞµÑ… Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²
generate_docs = PythonOperator(task_id='documentation', ...)

# Ğ“Ñ€Ğ°Ñ„
parse >> parallel >> generate_docs

# Ğ’Ñ€ĞµĞ¼Ñ: 10 (parse) + 12 (max Ğ¸Ğ· 4 Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ñ…) + 2 (docs) = 24 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹
# Ğ’Ğ¼ĞµÑÑ‚Ğ¾: 30-47 Ğ¼Ğ¸Ğ½ÑƒÑ‚
```

**Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ:**
- Ğ›ÑƒÑ‡ÑˆĞ¸Ğ¹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹: 47 â†’ 24 Ğ¼Ğ¸Ğ½ (-49%)
- Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹: 38 â†’ 24 Ğ¼Ğ¸Ğ½ (-37%)

---

## ğŸ“Š Ğ¡Ğ ĞĞ’ĞĞ•ĞĞ˜Ğ• FOOTPRINT

### Ğ ĞµÑÑƒÑ€ÑÑ‹ (RAM + CPU):

**Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹ A: ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ğµ**
```
Ğ‘Ğ«Ğ›Ğ (Celery only):
  Celery Worker:      200 MB RAM, 0.5 CPU
  Celery Beat:        50 MB RAM, 0.1 CPU
  Redis:              100 MB RAM, 0.2 CPU
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Ğ˜Ğ¢ĞĞ“Ğ:             350 MB RAM, 0.8 CPU

Ğ¡Ğ¢ĞĞ›Ğ (Airflow + Celery):
  Airflow Postgres:   200 MB RAM, 0.2 CPU
  Airflow Webserver:  400 MB RAM, 0.3 CPU
  Airflow Scheduler:  300 MB RAM, 0.4 CPU
  Airflow Worker:     500 MB RAM, 1.0 CPU
  Celery (Ğ¾ÑÑ‚Ğ°ĞµÑ‚ÑÑ):  350 MB RAM, 0.8 CPU
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Ğ˜Ğ¢ĞĞ“Ğ:            1,750 MB RAM, 2.7 CPU

Ğ ĞĞ—ĞĞ˜Ğ¦Ğ: +1,400 MB RAM (+400%), +1.9 CPU (+238%)
```

**Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ (AWS EC2):**
- t3.medium (4 GB RAM, 2 vCPU): $30/Ğ¼ĞµÑ
- Ğ‘Ñ‹Ğ»Ğ¾: ÑƒĞºĞ»Ğ°Ğ´Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ
- Ğ¡Ñ‚Ğ°Ğ»Ğ¾: Ğ½ÑƒĞ¶ĞµĞ½ t3.large (8 GB, 2 vCPU): $60/Ğ¼ĞµÑ
- **Ğ”Ğ¾Ğ¿. Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹: +$30/Ğ¼ĞµÑ ($360/Ğ³Ğ¾Ğ´)**

---

## âš–ï¸ Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞĞ¯ ĞĞ¦Ğ•ĞĞšĞ

### Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹ A (ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ):

**PROS:**
- âœ… ML Pipeline Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ Ğ½Ğ° 43%
- âœ… Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
- âœ… ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼ Ğ¸Ğ· ĞºĞ¾Ñ€Ğ¾Ğ±ĞºĞ¸

**CONS:**
- âŒ +$360/Ğ³Ğ¾Ğ´ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°
- âŒ +80 Ñ‡Ğ°ÑĞ¾Ğ² Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ ($4,000)
- âŒ Learning curve

**ROI:** 268% (Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ³Ğ¾Ğ´)

**Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚:** ğŸŸ¡ **ĞĞŸĞ¦Ğ˜ĞĞĞĞ›Ğ¬ĞĞ** (ĞµÑĞ»Ğ¸ ML ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµĞ½)

---

### Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹ B (Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ):

**PROS:**
- âœ… ML + EDT pipelines Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹
- âœ… Ğ•Ğ´Ğ¸Ğ½Ñ‹Ğ¹ UI Ğ´Ğ»Ñ Ğ²ÑĞµĞ³Ğ¾
- âœ… Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ 50+ Ñ‡Ğ°ÑĞ¾Ğ²/Ğ³Ğ¾Ğ´

**CONS:**
- âŒ +$500/Ğ³Ğ¾Ğ´ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°
- âŒ +120 Ñ‡Ğ°ÑĞ¾Ğ² Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ ($6,000)
- âŒ Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ complexity

**ROI:** 180% (Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ³Ğ¾Ğ´)

**Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚:** âš ï¸ **ĞĞ• Ğ Ğ•ĞšĞĞœĞ•ĞĞ”Ğ£Ğ•Ğ¢Ğ¡Ğ¯** (ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾)

---

### Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹ C (ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ):

**Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚:** âŒ **ĞšĞĞ¢Ğ•Ğ“ĞĞ Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜ ĞĞ• Ğ Ğ•ĞšĞĞœĞ•ĞĞ”Ğ£Ğ•Ğ¢Ğ¡Ğ¯** (over-engineering)

---

## ğŸ¯ ĞšĞĞĞšĞ Ğ•Ğ¢ĞĞĞ¯ Ğ Ğ•ĞšĞĞœĞ•ĞĞ”ĞĞ¦Ğ˜Ğ¯

### âœ… Ğ§Ğ¢Ğ Ğ”Ğ•Ğ›ĞĞ¢Ğ¬ Ğ¡Ğ•Ğ™Ğ§ĞĞ¡:

**Ğ’Ğ¼ĞµÑÑ‚Ğ¾ Airflow - ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Celery:**

```python
# 1. Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼ Ğ² Celery (8 Ñ‡Ğ°ÑĞ¾Ğ²)
from celery import group

@celery_app.task
def retrain_all_models_parallel():
    """ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ‡ĞµÑ€ĞµĞ· Celery groups"""
    job = group(
        retrain_model.s('classification'),
        retrain_model.s('regression'),
        retrain_model.s('clustering'),
        retrain_model.s('ranking'),
        retrain_model.s('recommendation'),
    )
    result = job.apply_async()
    return result.get()  # Ğ–Ğ´ĞµĞ¼ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ²ÑĞµÑ…

# Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ: 75 Ğ¼Ğ¸Ğ½ â†’ 15 Ğ¼Ğ¸Ğ½
# Ğ—Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹: 8 Ñ‡Ğ°ÑĞ¾Ğ²
# Ğ‘ĞµĞ· overhead Airflow!
```

**2. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ bash orchestrator Ğ´Ğ»Ñ EDT (6 Ñ‡Ğ°ÑĞ¾Ğ²)**
```bash
# scripts/run_full_edt_analysis.sh
# + Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼ Ñ‡ĞµÑ€ĞµĞ· background jobs
# + error handling
# + Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

Ğ—Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹: 6 Ñ‡Ğ°ÑĞ¾Ğ²
Ğ’Ñ‹Ğ³Ğ¾Ğ´Ğ°: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±ĞµĞ· Airflow
```

**3. Ğ£Ğ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Flower monitoring (12 Ñ‡Ğ°ÑĞ¾Ğ²)**
```
- Custom Grafana dashboard Ğ´Ğ»Ñ Celery
- Email alerts Ğ¿Ñ€Ğ¸ failures
- Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ (Ñ‡ĞµÑ€ĞµĞ· Prometheus)

Ğ—Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹: 12 Ñ‡Ğ°ÑĞ¾Ğ²
Ğ’Ñ‹Ğ³Ğ¾Ğ´Ğ°: 70% Ğ¾Ñ‚ Airflow UI Ğ·Ğ° 15% ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
```

**Ğ˜Ğ¢ĞĞ“Ğ:**
- Ğ—Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹: 26 Ñ‡Ğ°ÑĞ¾Ğ² ($1,300)
- Ğ’Ñ‹Ğ³Ğ¾Ğ´Ğ°: 60-70% Ğ¾Ñ‚ Airflow
- RAM: Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹
- **ROI: 600%+** â­

---

## ğŸ“ Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•

### Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° 1C AI Stack (Nov 2025):

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                           â•‘
â•‘  Ğ Ğ•ĞšĞĞœĞ•ĞĞ”ĞĞ¦Ğ˜Ğ¯: ĞĞ• Ğ’ĞĞ•Ğ”Ğ Ğ¯Ğ¢Ğ¬ AIRFLOW Ğ¡Ğ•Ğ™Ğ§ĞĞ¡                â•‘
â•‘                                                           â•‘
â•‘  ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°: Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ > Value Ğ´Ğ»Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ°        â•‘
â•‘                                                           â•‘
â•‘  ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ°:                                           â•‘
â•‘  â†’ Ğ£Ğ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Celery (26 Ñ‡Ğ°ÑĞ¾Ğ², $1,300)                    â•‘
â•‘  â†’ 60-70% Ğ²Ñ‹Ğ³Ğ¾Ğ´ Airflow Ğ·Ğ° 32% ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸                 â•‘
â•‘                                                           â•‘
â•‘  ĞŸĞµÑ€ĞµÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ: Q2 2025 (Ğ¿Ñ€Ğ¸ users >1,000)                â•‘
â•‘                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚:** ğŸŸ¢ LOW (ĞµÑÑ‚ÑŒ Ğ±Ğ¾Ğ»ĞµĞµ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸)

**Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:** âœ… ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½, Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¾

---

**Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ğ´Ğ»Ñ reference:**
- Ğ­Ñ‚Ğ¾Ñ‚ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚: Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¸
- AIRFLOW_DEEP_ANALYSIS_NOV_6_2025.md: Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
- AIRFLOW_DETAILED_COMPARISON.md: ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (Ğ´Ğ»Ñ reference)


